{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700ed447",
   "metadata": {},
   "source": [
    "### TTS Finetune Workflow using TAO\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "![image](https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png)\n",
    "\n",
    "\n",
    "### The workflow in a nutshell\n",
    "\n",
    "- Get sample datasets (or bring your own)\n",
    "- Creating source and target datasets\n",
    "- Upload speech dataset to the service\n",
    "- Creating a spectrogram generator model experiment\n",
    "- Getting a PTM from NGC\n",
    "- Actions\n",
    "    - Dataset convert\n",
    "    - Pitch stats to compute fmin, fmax, pitch_avg, pitch_std\n",
    "    - Finetune model\n",
    "    - Infer to produce data for HiFiGan\n",
    "- Download inferred data and process it to be compatible with hifigan\n",
    "- Create a vocoder model experiment\n",
    "- Upload dataset to service\n",
    "- Get a PTM for vocoder\n",
    "- Finetune vocoder\n",
    "- Inference on sample sentences using both fast_pitch and hifigan\n",
    "   \n",
    "**Other TAO Actions**\n",
    "\n",
    "- Export  \n",
    "- Train (from scratch)\n",
    "\n",
    "**Note**\n",
    "\n",
    "- We assume first dataset in train_datasets is source and second is target. This is not enforced in the API\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [Create source and target datasets for fast_pitch](#head-1)\n",
    "1. [List the created datasets](#head-2)\n",
    "1. [Create model ](#head-3)\n",
    "1. [List models](#head-4)\n",
    "1. [Assign train, eval datasets](#head-5)\n",
    "1. [Assign PTM](#head-6)\n",
    "1. [Actions](#head-7)\n",
    "1. [Dataset convert](#head-8)\n",
    "1. [Pitch Stats](#head-9)\n",
    "1. [Finetune](#head-10)\n",
    "1. [Infer](#head-11)\n",
    "1. [Convert inference output to a mel_spectrogram dataset](#head-12)\n",
    "1. [Vocoder](#head-13)\n",
    "1. [Create dataset and upload mel data](#head-14)\n",
    "1. [Create model, add train and eval datasets, select and add ptm](#head-15)\n",
    "1. [Vocoder finetune](#head-16)\n",
    "1. [Inference from raw sentences](#head-17)\n",
    "1. [Create a raw dataset to perform vocoder inference on](#head-18)\n",
    "1. [Vocoder inference on raw data](#head-19)\n",
    "1. [Vocoder inference on raw data from spectro_gen](#head-20)\n",
    "1. [Delete dataset sample](#head-21)\n",
    "1. [Delete model sample](#head-22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbe417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03384d6",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "1. Assign a workdir in FIXME1\n",
    "2. Fix the host_url variable in FIXME 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define workspaces and other variables\n",
    "\n",
    "workdir = \"/PATH/TO/EXPERIMENT/DIRECTORY\" # FIXME1\n",
    "host_url = \"http://10.233.90.104:8000\" # FIXME2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fdd9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = str(uuid.uuid4())\n",
    "print(\"New user ID created\",user_id)\n",
    "base_url = f\"{host_url}/api/v1/user/{user_id}\"\n",
    "print(\"API Calls will be forwarded to\",base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9a300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating workdir\n",
    "if not os.path.isdir(workdir):\n",
    "    os.makedirs(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f1e46",
   "metadata": {},
   "source": [
    "### Create source and target datasets for fast_pitch <a class=\"anchor\" id=\"head-1\"></a>\n",
    "\n",
    "For the rest of this notebook, it is assumed that you have:\n",
    "\n",
    " - Pretrained FastPitch and HiFiGAN models that were trained on LJSpeech sampled at 22kHz\n",
    " \n",
    "In the case that you are not using a TTS model trained on LJSpeech at the correct sampling rate. Please ensure that you have the original data, including wav files and a .json manifest file. If you have a TTS model but not at 22kHz, please ensure that you set the correct sampling rate, and fft parameters.\n",
    "\n",
    "For the rest of the notebook, we will be using a toy dataset consisting of 5 mins of audio. This dataset is for demo purposes only. For a good quality model, we recommend at least 30 minutes of audio. We recommend using the [NVIDIA Custom Voice Recorder](https://developer.nvidia.com/riva-voice-recorder-early-access) tool, to generate a good dataset for finetuning.\n",
    "\n",
    "Let's first download the original LJSpeech dataset. We download the toy dataset after. Then, using the API, we create these datasets and upload them to the service in the required format. Note that for the ljspeech source data, we need to run the convert action in order to create manifest files from the metadata.csv\n",
    "\n",
    "The first step downloads audio to text file lists from NVIDIA for LJSpeech and generates the manifest files. If you use your own dataset, you have to generate three files: `ljs_audio_text_train_filelist.txt`, `ljs_audio_text_val_filelist.txt`, `ljs_audio_text_test_filelist.txt` yourself and place it inside the ljspeech directory created below. Those files correspond to your train / val / test split. For each text file, the number of rows should be equal to number of samples in this split and each row should be like:\n",
    "\n",
    "```\n",
    "DUMMY/<file_name>.wav|<text_of_the_audio>\n",
    "```\n",
    "\n",
    "An example row is:\n",
    "\n",
    "```\n",
    "DUMMY/LJ045-0096.wav|Mrs. De Mohrenschildt thought that Oswald,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc24465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download source ljspeech dataset\n",
    "! wget -O ljspeech.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782541bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting and moving the data to the correct directories.\n",
    "! tar -xvf ljspeech.tar.bz2\n",
    "! rm -rf ljspeech\n",
    "! mv LJSpeech-1.1 ljspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309557f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create \"ljspeech\" format dataset\n",
    "! rm ljspeech.tar.bz2\n",
    "! tar -czvf ljspeech.tar.gz ljspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7874c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download target dataset\n",
    "!wget https://nemo-public.s3.us-east-2.amazonaws.com/6097_5_mins.tar.gz  # Contains 10MB of data\n",
    "!tar -xzf 6097_5_mins.tar.gz\n",
    "!sed -i \"s@\\\"audio_filepath\\\": \\\"audio/@\\\"audio_filepath\\\": \\\"audio/@g\" 6097_5_mins/manifest.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93efd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_path =  \"ljspeech.tar.gz\" # FIX if using own source dataset\n",
    "target_data_path =  \"6097_5_mins.tar.gz\" # FIX if using own target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bebdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create\n",
    "ds_type = \"speech\"\n",
    "ds_format = \"ljspeech\"\n",
    "data = json.dumps({\"type\":ds_type,\"format\":ds_format})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "source_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68bac4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload\n",
    "files = [(\"file\",open(source_data_path,\"rb\"))]\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{source_dataset_id}/upload\"\n",
    "\n",
    "response = requests.post(endpoint, files=files)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "ds_type = \"speech\"\n",
    "ds_format = \"custom\"\n",
    "data = json.dumps({\"type\":ds_type,\"format\":ds_format})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "target_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c537fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload\n",
    "files = [(\"file\",open(target_data_path,\"rb\"))]\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{target_dataset_id}/upload\"\n",
    "\n",
    "response = requests.post(endpoint, files=files)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e3a61",
   "metadata": {},
   "source": [
    "### List the created datasets <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed095f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# print(response.json()) ## Uncomment for verbose list output\n",
    "for rsp in response.json():\n",
    "    print(rsp[\"id\"],rsp[\"type\"],rsp[\"format\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ac2e7",
   "metadata": {},
   "source": [
    "### Create model  <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03997247",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_arch = \"spectro_gen\"\n",
    "encode_key = \"tlt_encode\"\n",
    "data = json.dumps({\"network_arch\":network_arch,\"encryption_key\":encode_key})\n",
    "\n",
    "endpoint = f\"{base_url}/model\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "fast_pitch_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb50f8",
   "metadata": {},
   "source": [
    "### List models <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c5838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/model\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# print(response.json()) ## Uncomment for verbose list output\n",
    "for rsp in response.json():\n",
    "    print(rsp[\"id\"],rsp[\"network_arch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de1ef1",
   "metadata": {},
   "source": [
    "### Assign train, eval datasets <a class=\"anchor\" id=\"head-5\"></a>\n",
    "\n",
    "- Note: make sure the order for train_datasets is [source ID, target ID]\n",
    "- eval_dataset is kept same as target for demo purposes\n",
    "- inference_dataset is kept as target for chaining with hifigan finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d45a9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_information = {\"train_datasets\":[source_dataset_id,target_dataset_id],\n",
    "                       \"eval_dataset\":target_dataset_id,\n",
    "                       \"inference_dataset\":target_dataset_id}\n",
    "data = json.dumps(dataset_information)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7108e0f",
   "metadata": {},
   "source": [
    "### Assign PTM <a class=\"anchor\" id=\"head-6\"></a>\n",
    "\n",
    "- Search for fastpitch on NGC\n",
    "- Assign it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e22adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained model for fastpitch\n",
    "model_list = f\"{base_url}/model\"\n",
    "response = requests.get(model_list)\n",
    "\n",
    "response_json = response.json()\n",
    "\n",
    "# Search for ptm with given ngc path\n",
    "ptm_id = None\n",
    "for rsp in response_json:\n",
    "    if \"fastpitch:1.4.0\" in rsp[\"ngc_path\"]:\n",
    "        ptm_id = rsp[\"id\"]\n",
    "        print(\"Metadata for model with requested NGC Path\")\n",
    "        print(rsp)\n",
    "        break\n",
    "fast_pitch_ptm = ptm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c1ef39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ptm_information = {\"ptm\":fast_pitch_ptm}\n",
    "data = json.dumps(ptm_information)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2898b8",
   "metadata": {},
   "source": [
    "### Actions <a class=\"anchor\" id=\"head-7\"></a>\n",
    "\n",
    "For all actions:\n",
    "1. Get default spec schema and derive the default values\n",
    "2. Modify defaults if needed\n",
    "3. Post spec dictionary to the service\n",
    "4. Run model action\n",
    "5. Monitor job using retrieve\n",
    "6. Download results using job download endpoint (if needed). Please download after job status goes to \"Done\" state. Else, you will get a HTTP 404 code returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2d4bb",
   "metadata": {},
   "source": [
    "### Dataset convert <a class=\"anchor\" id=\"head-8\"></a>\n",
    "\n",
    "- First we generate manifest for the \"source\" ljspeech dataset by running the convert action on the ljspeech format dataset\n",
    "- Then we merge the ljspeech with target dataset by running the model dataset_convert action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d20af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/dataset/{source_dataset_id}/specs/convert/schema\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "## No changes to spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57727ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{source_dataset_id}/specs/convert\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = None\n",
    "actions = [\"convert\"]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{source_dataset_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "lj_job_id = response.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325fc34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell, please be patient as this may take a while to go to \"Done\" status\n",
    "\n",
    "job_id = lj_job_id\n",
    "endpoint = f\"{base_url}/dataset/{source_dataset_id}/job/{job_id}\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda6027",
   "metadata": {},
   "source": [
    "### Merging manifest files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/specs/dataset_convert/schema\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4103b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "# NONE FOR DATASET_CONVERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/specs/dataset_convert\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = None\n",
    "actions = [\"dataset_convert\"]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "job_map[\"dataset_convert\"] = response.json()[0]\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad234ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "\n",
    "job_id = job_map['dataset_convert']\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/job/{job_id}\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651b108",
   "metadata": {},
   "source": [
    "### Pitch Stats <a class=\"anchor\" id=\"head-9\"></a>\n",
    "- Run this on the target dataset to check visually if the pitch frequencies are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc934633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pitch_stats\n",
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/dataset/{target_dataset_id}/specs/pitch_stats/schema\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98720280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "specs[\"pitch_fmin\"] = 80\n",
    "specs[\"pitch_fmax\"] = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{target_dataset_id}/specs/pitch_stats\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f970fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = None\n",
    "actions = [\"pitch_stats\"]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{target_dataset_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "job_map[\"pitch_stats\"] = response.json()[0]\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6581978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "\n",
    "job_id = job_map['pitch_stats']\n",
    "endpoint = f\"{base_url}/dataset/{target_dataset_id}/job/{job_id}\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372b887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download pitch stats output\n",
    "job_id = job_map[\"pitch_stats\"]\n",
    "endpoint = f'{base_url}/dataset/{target_dataset_id}/job/{job_id}/download'\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# Save\n",
    "temptar = f'{job_id}.tar.gz'\n",
    "with open(temptar, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "print(\"Untarring\")\n",
    "# Untar to destination\n",
    "tar_command = f'tar -xvf {temptar} -C {workdir}/'\n",
    "os.system(tar_command)\n",
    "os.remove(temptar)\n",
    "print(f\"Results at {workdir}/{job_id}\")\n",
    "saved_dir = f\"{workdir}/{job_id}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7608dea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize pitch stats output\n",
    "!pip3 install matplotlib==3.3.3\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from math import ceil\n",
    "from IPython.display import Image\n",
    "\n",
    "valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n",
    "\n",
    "def visualize_images(image_dir, num_cols=2, num_images=10):\n",
    "    \"\"\"Visualize images in the notebook.\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Path to the directory containing images.\n",
    "        num_cols (int): Number of columns.\n",
    "        num_images (int): Number of images.\n",
    "\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(image_dir)\n",
    "    num_rows = int(ceil(float(num_images) / float(num_cols)))\n",
    "    f, axarr = plt.subplots(num_rows, num_cols, figsize=[240,90])\n",
    "    f.tight_layout()\n",
    "    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n",
    "         if os.path.splitext(image)[1].lower() in valid_image_ext]\n",
    "    for idx, img_path in enumerate(a[:num_images]):\n",
    "        col_id = idx % num_cols\n",
    "        row_id = idx // num_cols\n",
    "        img = plt.imread(img_path)\n",
    "        axarr[row_id, col_id].imshow(img)\n",
    "visualize_images(saved_dir, num_cols=5, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e97f4",
   "metadata": {},
   "source": [
    "### Finetune <a class=\"anchor\" id=\"head-10\"></a>\n",
    "\n",
    "- Please modify ```specs[\"trainer\"][\"max_epochs\"]``` to modify number of epochs you want to run training for. Default is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/specs/finetune/schema\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes from pitch_stats job\n",
    "specs[\"n_speakers\"] = 1\n",
    "specs[\"pitch_fmin\"] = 80\n",
    "specs[\"pitch_fmax\"] = 800\n",
    "specs[\"pitch_avg\"] = 117.27540199742586\n",
    "specs[\"pitch_std\"] = 22.1851002822779\n",
    "specs[\"trainer\"] = {\"max_epochs\":100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f82e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/specs/finetune\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55bf3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = None\n",
    "actions = [\"finetune\"]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "job_map[\"spectro_gen_finetune\"] = response.json()[0]\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67cba80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "\n",
    "job_id = job_map['spectro_gen_finetune']\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/job/{job_id}\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3521a2ca",
   "metadata": {},
   "source": [
    "### Infer <a class=\"anchor\" id=\"head-11\"></a>\n",
    "\n",
    "- Infer runs inference on previously set inference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/specs/infer/schema\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67087da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "specs[\"mode\"] = \"infer_hifigan_ft\"\n",
    "specs[\"speaker\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/specs/infer\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d21609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = job_map[\"spectro_gen_finetune\"]\n",
    "actions = [\"infer\"]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "job_map[\"spectro_gen_infer\"] = response.json()[0]\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "\n",
    "job_id = job_map['spectro_gen_infer']\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/job/{job_id}\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063c2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download infer output for chaining with vocoder\n",
    "# Download job contents once the above job shows \"Done\" status\n",
    "job_id = job_map[\"spectro_gen_infer\"]\n",
    "endpoint = f'{base_url}/model/{fast_pitch_id}/job/{job_id}/download'\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# Save\n",
    "temptar = f'{job_id}.tar.gz'\n",
    "with open(temptar, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "print(\"Untarring\")\n",
    "# Untar to destination\n",
    "tar_command = f'tar -xvf {temptar} -C {workdir}/'\n",
    "os.system(tar_command)\n",
    "os.remove(temptar)\n",
    "print(f\"Results at {workdir}/{job_id}\")\n",
    "infer_out_path = f\"{workdir}/{job_id}\"\n",
    "\n",
    "os.remove(infer_out_path+\"/status.json\")\n",
    "os.remove(infer_out_path+\"/infer.log\")\n",
    "os.remove(infer_out_path+\"/logs_from_toolkit.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a879371",
   "metadata": {},
   "source": [
    "### Convert inference output to a mel_spectrogram dataset <a class=\"anchor\" id=\"head-12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b51a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy target data to workdir\n",
    "!cp $target_data_path $workdir\n",
    "\n",
    "# Untar the target data inside workdir\n",
    "target_tar_name = target_data_path.split(\"/\")[-1]\n",
    "tar_command = f'tar -xvf {workdir}/{target_tar_name} -C {workdir}/'\n",
    "os.system(tar_command)\n",
    "os.remove(f\"{workdir}/{target_tar_name}\")\n",
    "\n",
    "# get the name of this untarred target dataset folder into $original_target_folder\n",
    "target_name = target_tar_name.rstrip(\".tar.gz\")\n",
    "original_target_folder = f\"{workdir}/{target_name}\".replace(\"//\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfa08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move it to the target folder\n",
    "!mv $infer_out_path $original_target_folder/mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = os.path.join(original_target_folder,\"manifest.json\")\n",
    "# append paths to manifest audio_filepath\n",
    "with open(manifest,\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "print(\"Number of lines in target data: \",len(lines))\n",
    "\n",
    "os.remove(manifest)\n",
    "\n",
    "with open(manifest,\"w\") as f:\n",
    "    cnt = 0\n",
    "    for line in lines:\n",
    "        line_dict = json.loads(line.strip(\"\\n\"))\n",
    "        line_dict[\"mel_filepath\"] = f\"mel_spectrogram/{cnt}.npy\"\n",
    "        f.write(json.dumps(line_dict)+\"\\n\")\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e326cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tar the updated mel-spectrogram appended dataset\n",
    "tarfilename = original_target_folder.split(\"/\")[-1]+\".tar.gz\"\n",
    "print(tarfilename)\n",
    "\n",
    "output_save = f'{workdir}/{tarfilename}'.replace(\"//\",\"/\")\n",
    "tar_command = f'tar -czvf {output_save} {original_target_folder}'\n",
    "os.system(tar_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_dataset_path = f\"{workdir}/{tarfilename}\".replace(\"//\",\"/\")\n",
    "mel_dataset_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013abbe",
   "metadata": {},
   "source": [
    "### Vocoder <a class=\"anchor\" id=\"head-13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6135be6e",
   "metadata": {},
   "source": [
    "### Create dataset and upload mel data <a class=\"anchor\" id=\"head-14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "ds_type = \"mel_spectrogram\"\n",
    "ds_format = \"hifigan\"\n",
    "data = json.dumps({\"type\":ds_type,\"format\":ds_format})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "mel_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1bd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload\n",
    "files = [(\"file\",open(mel_dataset_path,\"rb\"))]\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{mel_dataset_id}/upload\"\n",
    "\n",
    "response = requests.post(endpoint, files=files)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# print(response.json()) ## Uncomment for verbose list output\n",
    "for rsp in response.json():\n",
    "    print(rsp[\"id\"],rsp[\"type\"],rsp[\"format\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2394dd",
   "metadata": {},
   "source": [
    "### Create model, add train and eval datasets, select and add ptm <a class=\"anchor\" id=\"head-15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d15ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_arch = \"vocoder\"\n",
    "encode_key = \"tlt_encode\"\n",
    "data = json.dumps({\"network_arch\":network_arch,\"encryption_key\":encode_key})\n",
    "\n",
    "endpoint = f\"{base_url}/model\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "vocoder_model_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd8056",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_information = {\"train_datasets\":[mel_dataset_id],\n",
    "                       \"eval_dataset\":mel_dataset_id}\n",
    "data = json.dumps(dataset_information)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained model for hifigan\n",
    "model_list = f\"{base_url}/model\"\n",
    "response = requests.get(model_list)\n",
    "\n",
    "response_json = response.json()\n",
    "\n",
    "# Search for ptm with given ngc path\n",
    "ptm_id = None\n",
    "for rsp in response_json:\n",
    "    if \"hifigan:1.0.0rc1\" in rsp[\"ngc_path\"]:\n",
    "        ptm_id = rsp[\"id\"]\n",
    "        print(\"Metadata for model with requested NGC Path\")\n",
    "        print(rsp)\n",
    "        break\n",
    "vocoder_ptm = ptm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5839e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ptm_information = {\"ptm\":vocoder_ptm}\n",
    "data = json.dumps(ptm_information)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df37d8",
   "metadata": {},
   "source": [
    "### Vocoder finetune <a class=\"anchor\" id=\"head-16\"></a>\n",
    "\n",
    "- Please modify ```specs[\"trainer\"][\"max_steps\"]``` to modify number of steps you want to run training for. Default is 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}/specs/finetune/schema\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297151ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "specs[\"trainer\"] = {\"max_steps\":1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}/specs/finetune\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db40665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = None\n",
    "actions = [\"finetune\"]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "job_map[\"vocoder_finetune\"] = response.json()[0]\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35c86f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "\n",
    "job_id = job_map['vocoder_finetune']\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}/job/{job_id}\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f6b4e",
   "metadata": {},
   "source": [
    "### Inference from raw sentences <a class=\"anchor\" id=\"head-17\"></a>\n",
    "\n",
    "- Take some sentences and run spectro_gen inference\n",
    "- Then use the output of this to generate vocoder inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024681e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .\",\n",
    "             \"director rob marshall went out gunning to make a great one .\",\n",
    "             \"uneasy mishmash of styles and genres .\"   \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa10350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/specs/infer/schema\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bcd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "specs[\"mode\"] = \"infer\"\n",
    "specs[\"input_batch\"] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7250593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/specs/infer\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = job_map[\"spectro_gen_finetune\"]\n",
    "actions = [\"infer\"]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "job_map[\"spectro_gen_infer_raw\"] = response.json()[0]\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "\n",
    "job_id = job_map['spectro_gen_infer_raw']\n",
    "endpoint = f\"{base_url}/model/{fast_pitch_id}/job/{job_id}\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1b53d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download infer output for chaining with vocoder\n",
    "# Download job contents once the above job shows \"Done\" status\n",
    "job_id = job_map[\"spectro_gen_infer_raw\"]\n",
    "endpoint = f'{base_url}/model/{fast_pitch_id}/job/{job_id}/download'\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# Save\n",
    "temptar = f'{job_id}.tar.gz'\n",
    "with open(temptar, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "print(\"Untarring\")\n",
    "# Untar to destination\n",
    "tar_command = f'tar -xvf {temptar} -C {workdir}/'\n",
    "os.system(tar_command)\n",
    "os.remove(temptar)\n",
    "print(f\"Results at {workdir}/{job_id}\")\n",
    "raw_infer_out_path = f\"{workdir}/{job_id}\"\n",
    "\n",
    "os.remove(raw_infer_out_path+\"/status.json\")\n",
    "os.remove(raw_infer_out_path+\"/infer.log\")\n",
    "os.remove(raw_infer_out_path+\"/logs_from_toolkit.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tar it so it can be uploaded\n",
    "foldername = job_map[\"spectro_gen_infer_raw\"]\n",
    "\n",
    "tar_command = f\"cd {workdir}; \\\n",
    "                mkdir raw; \\\n",
    "                mv {foldername} raw/mel_spectrogram ; \\\n",
    "                tar -czvf raw_melspectrograms.tar.gz raw; \\\n",
    "                cd -\"\n",
    "print(os.system(tar_command))\n",
    "raw_tarfile = f'{workdir}/raw_melspectrograms.tar.gz'.replace(\"//\",\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee6278",
   "metadata": {},
   "source": [
    "### Create a raw dataset to perform vocoder inference on <a class=\"anchor\" id=\"head-18\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "ds_type = \"mel_spectrogram\"\n",
    "ds_format = \"raw\"\n",
    "data = json.dumps({\"type\":ds_type,\"format\":ds_format})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "raw_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c8b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload\n",
    "files = [(\"file\",open(raw_tarfile,\"rb\"))]\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{raw_dataset_id}/upload\"\n",
    "\n",
    "response = requests.post(endpoint, files=files)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052a69c",
   "metadata": {},
   "source": [
    "### Vocoder inference on raw data <a class=\"anchor\" id=\"head-19\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83816282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this inference dataset to vocoder model\n",
    "dataset_information = {\"inference_dataset\":raw_dataset_id}\n",
    "data = json.dumps(dataset_information)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff6ff8",
   "metadata": {},
   "source": [
    "### Vocoder inference on raw data from spectro_gen <a class=\"anchor\" id=\"head-20\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aae1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}/specs/infer/schema\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e92917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31272679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}/specs/infer\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6807b1a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = job_map[\"vocoder_finetune\"]\n",
    "actions = [\"infer\"]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "job_map[\"vocoder_infer_raw\"] = response.json()[0]\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "\n",
    "job_id = job_map['vocoder_infer_raw']\n",
    "endpoint = f\"{base_url}/model/{vocoder_model_id}/job/{job_id}\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download infer output of vocoder\n",
    "# Download job contents once the above job shows \"Done\" status\n",
    "job_id = job_map[\"vocoder_infer_raw\"]\n",
    "endpoint = f'{base_url}/model/{vocoder_model_id}/job/{job_id}/download'\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# Save\n",
    "temptar = f'{job_id}.tar.gz'\n",
    "with open(temptar, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "print(\"Untarring\")\n",
    "# Untar to destination\n",
    "tar_command = f'tar -xvf {temptar} -C {workdir}/'\n",
    "os.system(tar_command)\n",
    "os.remove(temptar)\n",
    "print(f\"Results at {workdir}/{job_id}\")\n",
    "raw_infer_wav_path = f\"{workdir}/{job_id}\"\n",
    "\n",
    "os.remove(raw_infer_wav_path+\"/status.json\")\n",
    "os.remove(raw_infer_wav_path+\"/infer.log\")\n",
    "os.remove(raw_infer_wav_path+\"/logs_from_toolkit.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02eaeac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!ls $raw_infer_wav_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d6488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython.display as ipd\n",
    "# change path of the file here\n",
    "ipd.Audio(f'{raw_infer_wav_path}/0.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8562bab5",
   "metadata": {},
   "source": [
    "### Delete dataset sample <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52bbc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "ds_type = \"mel_spectrogram\"\n",
    "ds_format = \"hifigan\"\n",
    "data = json.dumps({\"type\":ds_type,\"format\":ds_format})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "random_ds = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# print(response.json()) ## Uncomment for verbose list output\n",
    "for rsp in response.json():\n",
    "    print(rsp[\"id\"],rsp[\"type\"],rsp[\"format\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76693a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/dataset/{random_ds}\"\n",
    "response = requests.delete(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# print(response.json()) ## Uncomment for verbose list output\n",
    "for rsp in response.json():\n",
    "    print(rsp[\"id\"],rsp[\"type\"],rsp[\"format\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4db0d",
   "metadata": {},
   "source": [
    "### Delete model sample <a class=\"anchor\" id=\"head-22\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_arch = \"vocoder\"\n",
    "encode_key = \"tlt_encode\"\n",
    "data = json.dumps({\"network_arch\":network_arch,\"encryption_key\":encode_key})\n",
    "\n",
    "endpoint = f\"{base_url}/model\"\n",
    "\n",
    "response = requests.post(endpoint,data=data)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "random_mdl = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cbba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/model\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# print(response.json()) ## Uncomment for verbose list output\n",
    "for rsp in response.json():\n",
    "    print(rsp[\"id\"],rsp[\"network_arch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/model/{random_mdl}\"\n",
    "response = requests.delete(endpoint)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e1a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/model\"\n",
    "\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "print(response)\n",
    "# print(response.json()) ## Uncomment for verbose list output\n",
    "for rsp in response.json():\n",
    "    print(rsp[\"id\"],rsp[\"network_arch\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
